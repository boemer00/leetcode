{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb5f6e4e",
   "metadata": {},
   "source": [
    "# Linked Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d03c4",
   "metadata": {},
   "source": [
    "Given the beginning of a singly linked list head, reverse the list, and return the new beginning of the list.\n",
    "\n",
    "**Example 1:**\n",
    "- Input: head = [0,1,2,3]\n",
    "- Output: [3,2,1,0]\n",
    "\n",
    "**Example 2:**\n",
    "- Input: head = []\n",
    "- Output: []\n",
    "\n",
    "\n",
    "**Constraints:**\n",
    "- 0 <= The length of the list <= 1000.\n",
    "- -1000 <= Node.val <= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for singly-linked list node.\n",
    "class Node:\n",
    "    def __init__(self, val=0, next=None):\n",
    "        self.val = val  # Initialize the node's value.\n",
    "        self.next = next  # Initialize the pointer to the next node.\n",
    "\n",
    "def reverse_linked_list(head):\n",
    "    \"\"\"\n",
    "    Function to reverse a singly linked list.\n",
    "    \n",
    "    Args:\n",
    "    head (Node): The head node of the singly linked list.\n",
    "    \n",
    "    Returns:\n",
    "    Node: The new head node of the reversed linked list.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize previous node as None (this will be the new tail).\n",
    "    prev = None\n",
    "    \n",
    "    # Start with the current node as the head of the list.\n",
    "    curr = head\n",
    "    \n",
    "    # Iterate through the linked list until you reach the end.\n",
    "    while curr:\n",
    "        # Store the next node before changing the current node's next pointer.\n",
    "        nxt = curr.next\n",
    "        \n",
    "        # Reverse the current node's pointer to point to the previous node.\n",
    "        curr.next = prev\n",
    "        \n",
    "        # Move the previous node to the current node.\n",
    "        prev = curr\n",
    "        \n",
    "        # Move to the next node in the original list.\n",
    "        curr = nxt\n",
    "    \n",
    "    # Return the new head of the reversed list (the previous tail).\n",
    "    return prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50f90f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Define the nodes of the linked list\n",
    "node1 = Node(1)\n",
    "node2 = Node(2)\n",
    "node3 = Node(3)\n",
    "node4 = Node(4)\n",
    "\n",
    "# Link the nodes\n",
    "node1.next = node2\n",
    "node2.next = node3\n",
    "node3.next = node4\n",
    "\n",
    "# Reverse the linked list\n",
    "reversed_head = reverse_linked_list(node1)\n",
    "\n",
    "# Print the reversed linked list\n",
    "curr = reversed_head\n",
    "\n",
    "while curr:\n",
    "    print(curr.val)\n",
    "    curr = curr.next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e0e93",
   "metadata": {},
   "source": [
    "## RL example from ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a36c8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Step 1: Define the Node class for storing state-action-reward triples.\n",
    "class Node:\n",
    "    def __init__(self, state, action, reward, next_node=None):\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        self.reward = reward\n",
    "        self.next = next_node\n",
    "\n",
    "# Step 2: Define the Linked List class to manage the sequence of states and actions.\n",
    "class LinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "    \n",
    "    def append(self, state, action, reward):\n",
    "        if not self.head:\n",
    "            self.head = Node(state, action, reward)\n",
    "        else:\n",
    "            current = self.head\n",
    "            while current.next:\n",
    "                current = current.next\n",
    "            current.next = Node(state, action, reward)\n",
    "\n",
    "    def iterate(self):\n",
    "        current = self.head\n",
    "        while current:\n",
    "            yield current\n",
    "            current = current.next\n",
    "\n",
    "# Step 3: Define a simple Q-learning algorithm with linked list to track episodes.\n",
    "class QLearningAgent:\n",
    "    def __init__(self, states, actions, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
    "        self.q_table = {state: {action: 0 for action in actions} for state in states}\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.actions = actions\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(self.actions)\n",
    "        else:\n",
    "            return max(self.q_table[state], key=self.q_table[state].get)\n",
    "\n",
    "    def learn(self, linked_list):\n",
    "        current = linked_list.head\n",
    "        while current:\n",
    "            state, action, reward = current.state, current.action, current.reward\n",
    "            next_state = current.next.state if current.next else None\n",
    "\n",
    "            if next_state:\n",
    "                best_next_action = max(self.q_table[next_state], key=self.q_table[next_state].get)\n",
    "                td_target = reward + self.gamma * self.q_table[next_state][best_next_action]\n",
    "            else:\n",
    "                td_target = reward  # No next state means the episode ended.\n",
    "\n",
    "            td_error = td_target - self.q_table[state][action]\n",
    "            self.q_table[state][action] += self.alpha * td_error\n",
    "\n",
    "            current = current.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54f76175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State S1: {'up': 0, 'down': 0, 'left': 0, 'right': -0.1}\n",
      "State S2: {'up': 0, 'down': 0, 'left': 0, 'right': -0.1}\n",
      "State S3: {'up': 0, 'down': 1.0, 'left': 0, 'right': 0}\n",
      "State S4: {'up': 0, 'down': 0, 'left': 0, 'right': 0}\n"
     ]
    }
   ],
   "source": [
    "# Example environment and agent interaction:\n",
    "states = ['S1', 'S2', 'S3', 'S4']  # Example states\n",
    "actions = ['up', 'down', 'left', 'right']  # Example actions\n",
    "\n",
    "# Create the Q-learning agent\n",
    "agent = QLearningAgent(states, actions)\n",
    "\n",
    "# Simulate an episode\n",
    "episode = LinkedList()\n",
    "episode.append('S1', 'right', -1)\n",
    "episode.append('S2', 'right', -1)\n",
    "episode.append('S3', 'down', 10)  # Reached the goal with a positive reward\n",
    "\n",
    "# Learn from the episode\n",
    "agent.learn(episode)\n",
    "\n",
    "# Check updated Q-values\n",
    "for state in agent.q_table:\n",
    "    print(f\"State {state}: {agent.q_table[state]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6eac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
